{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQ6wc2HE0pke"
      },
      "source": [
        "# **Experiment Notebook**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFVpE17Ahezu"
      },
      "source": [
        "---\n",
        "## 0. Setup Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jM39DExClCc5"
      },
      "source": [
        "### 0.b Disable Warnings Messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6FneOmBfka9G"
      },
      "outputs": [],
      "source": [
        "# Do not modify this code\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXFKfa2tp1ch"
      },
      "source": [
        "### 0.d Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBEAwdncnlAx"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import altair as alt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQgxLRrvjiJb"
      },
      "source": [
        "---\n",
        "## A. Project Description\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_tile(size=\"h3\", key=None, value=None):\n",
        "    \"\"\"\n",
        "    Display a formatted HTML tile in a Jupyter notebook.\n",
        "    Args:\n",
        "        size (str): HTML heading size, e.g., \"h1\", \"h2\", \"h3\".\n",
        "        key (str): Unique identifier for the tile.\n",
        "        value (str): Content to display in the tile.\n",
        "    \"\"\"\n",
        "    from IPython.display import display, HTML\n",
        "    html = f'<{size} id=\"{key}\">{value}</{size}>'\n",
        "    display(HTML(html))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTf0Pg6Z2v-Z"
      },
      "outputs": [],
      "source": [
        "\n",
        "business_objective = \"\"\"\n",
        "The goal of this project is to develop a predictive model to classify student poor performance into categories such as \"Excellent,\" \"Good,\" \"Average,\" and \"Poor,\" enabling early identification of at-risk students. The results will help universities allocate resources effectively, tailor interventions, and improve academic outcomes. Accurate predictions can lead to better student support and institutional success, while incorrect results risk misallocating resources, harming student experiences, and potentially damaging the institution's credibility.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "exnz6agQ2wFg",
        "outputId": "af3c45ad-2aed-4577-93d9-b1cb94fef431"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<h3 id=\"business_objective\">\n",
              "The goal of this project is to develop a predictive model to classify student poor performance into categories such as \"Excellent,\" \"Good,\" \"Average,\" and \"Poor,\" enabling early identification of at-risk students. The results will help universities allocate resources effectively, tailor interventions, and improve academic outcomes. Accurate predictions can lead to better student support and institutional success, while incorrect results risk misallocating resources, harming student experiences, and potentially damaging the institution's credibility.\n",
              "</h3>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Do not modify this code\n",
        "print_tile(size=\"h3\", key='business_objective', value=business_objective)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q1Bzcejvfpm"
      },
      "source": [
        "---\n",
        "## B. Experiment Description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qng9pUoU21Kp"
      },
      "outputs": [],
      "source": [
        "\n",
        "experiment_hypothesis =  \"\"\"\n",
        "The hypothesis to test in this project is: **\"Student performance can be accurately predicted using key academic, behavioral, and socio-economic features such as GPA, study hours, social media usage, and attendance rates.\"** The question seeks to determine how well these factors correlate with and influence academic success, enabling classification into performance categories like \"Excellent,\" \"Good,\" \"Average,\" and \"Poor.\"\n",
        "\n",
        "This hypothesis is worthwhile because accurate predictions can allow institutions to identify at-risk students early, provide tailored interventions, and enhance academic outcomes. It also helps optimize resource allocation by focusing efforts on students who need the most support. By understanding the significant predictors of performance, institutions can make data-driven decisions, enhancing both individual student success and overall educational quality. This insight provides a robust foundation for sustainable improvements in academic strategies.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "3F9fpCzf21YI",
        "outputId": "d8211cc5-acb9-4be2-d243-d84ea5806914"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<h3 id=\"experiment_hypothesis\">\n",
              "The hypothesis to test in this project is: **\"Student performance can be accurately predicted using key academic, behavioral, and socio-economic features such as GPA, study hours, social media usage, and attendance rates.\"** The question seeks to determine how well these factors correlate with and influence academic success, enabling classification into performance categories like \"Excellent,\" \"Good,\" \"Average,\" and \"Poor.\"\n",
              "\n",
              "This hypothesis is worthwhile because accurate predictions can allow institutions to identify at-risk students early, provide tailored interventions, and enhance academic outcomes. It also helps optimize resource allocation by focusing efforts on students who need the most support. By understanding the significant predictors of performance, institutions can make data-driven decisions, enhancing both individual student success and overall educational quality. This insight provides a robust foundation for sustainable improvements in academic strategies.\n",
              "</h3>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Do not modify this code\n",
        "print_tile(size=\"h3\", key='experiment_hypothesis', value=experiment_hypothesis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Ke5AG7A21dx"
      },
      "outputs": [],
      "source": [
        "\n",
        "experiment_expectations =\"\"\"\n",
        "The expected outcome of the experiment is to create a model that predicts student performance categories—\"Excellent,\" \"Good,\" \"Average,\" \"Poor.\"\n",
        "### Possible Scenarios:\n",
        "1. **Best Case**: The model's performance improves, reaching over 80% accuracy with balanced metrics across all classes, enabling effective interventions for students.\n",
        "2. **Moderate Case**: Metrics remain skewed toward dominant classes (\"Poor\"), and minority classes like \"Excellent\" and \"Good\" have low recall, requiring adjustments in features or algorithms.\n",
        "3. **Worst Case**: The model fails to generalize, achieving accuracy below 50%, leading to misallocated resources and diminished institutional trust.\n",
        "\n",
        "These outcomes highlight the need for refining the model to improve predictions for minority classes while leveraging its strength in dominant categories.\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "Aal6ECC821nJ",
        "outputId": "3cf33c49-2126-4d55-fbfe-83861cb23527"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<h3 id=\"experiment_expectations\">\n",
              "The expected outcome of the experiment is to create a model that predicts student performance categories—\"Excellent,\" \"Good,\" \"Average,\" \"Poor.\"\n",
              "### Possible Scenarios:\n",
              "1. **Best Case**: The model's performance improves, reaching over 80% accuracy with balanced metrics across all classes, enabling effective interventions for students.\n",
              "2. **Moderate Case**: Metrics remain skewed toward dominant classes (\"Poor\"), and minority classes like \"Excellent\" and \"Good\" have low recall, requiring adjustments in features or algorithms.\n",
              "3. **Worst Case**: The model fails to generalize, achieving accuracy below 50%, leading to misallocated resources and diminished institutional trust.\n",
              "\n",
              "These outcomes highlight the need for refining the model to improve predictions for minority classes while leveraging its strength in dominant categories.\n",
              "\n",
              "</h3>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Do not modify this code\n",
        "print_tile(size=\"h3\", key='experiment_expectations', value=experiment_expectations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0zsEPshwy1K"
      },
      "source": [
        "---\n",
        "## C. Data Understanding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "NKgOzSn-w0eq"
      },
      "outputs": [],
      "source": [
        "# Do not modify this code\n",
        "# Load training data\n",
        "try:\n",
        "  X_train = pd.read_csv('../data/processed/X_train.csv')\n",
        "  y_train = pd.read_csv('../data/processed/y_train.csv')\n",
        "\n",
        "  X_val = pd.read_csv('../data/processed/X_val.csv')\n",
        "  y_val = pd.read_csv('../data/processed/y_val.csv')\n",
        "\n",
        "  X_test = pd.read_csv('../data/processed/X_test.csv')\n",
        "  y_test = pd.read_csv('../data/processed/y_test.csv')\n",
        "except Exception as e:\n",
        "  print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NCwQQFkU3v5"
      },
      "source": [
        "---\n",
        "## D. Feature Selection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfC-DLKv4AuM",
        "outputId": "74179747-7ed2-4ab5-a731-c0bf4072b979"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "student_id                       -0.416043\n",
            "age                              -0.046171\n",
            "hsc_year                          0.188994\n",
            "current _semester                -0.184882\n",
            "study_hours                       0.236444\n",
            "social_media_hours               -0.443580\n",
            "average_attendance               -0.242111\n",
            "skills_development_hours         -0.048071\n",
            "previous_gpa                      0.687628\n",
            "current_gpa                      -0.542631\n",
            "completed_credits                -0.254523\n",
            "house_income                     -0.259291\n",
            "gpa_consistency                   0.332170\n",
            "social_media_impact               0.464983\n",
            "income_academic_score            -0.261522\n",
            "english_proficiency_encoded      -0.063948\n",
            "birth_country_AU                 -0.076070\n",
            "birth_country_BR                  0.007581\n",
            "birth_country_CA                 -0.033834\n",
            "birth_country_IE                  0.050013\n",
            "birth_country_IN                  0.051579\n",
            "birth_country_NZ                 -0.026911\n",
            "birth_country_PH                  0.005309\n",
            "birth_country_TH                  0.069651\n",
            "birth_country_US                  0.050013\n",
            "birth_country_ZA                  0.061342\n",
            "scholarship_No                   -0.329113\n",
            "scholarship_Yes                   0.329113\n",
            "university_transport_No          -0.045174\n",
            "university_transport_Yes          0.045174\n",
            "learning_mode_Offline             0.127438\n",
            "learning_mode_Online             -0.127438\n",
            "on_probation_No                   0.292227\n",
            "on_probation_Yes                 -0.292227\n",
            "is_suspended_No                   0.044970\n",
            "is_suspended_Yes                 -0.044970\n",
            "relationship_Engaged             -0.023254\n",
            "relationship_In a relationship   -0.194657\n",
            "relationship_Married             -0.127641\n",
            "relationship_Single               0.246625\n",
            "target                            1.000000\n",
            "Name: target, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "train_data = pd.concat([X_train, y_train], axis=1)\n",
        "correlation_matrix = train_data.corr()\n",
        "\n",
        "correlation_with_y_train = correlation_matrix['target']\n",
        "\n",
        "# Print the correlations\n",
        "print(correlation_with_y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-d6jn5HLvWf",
        "outputId": "36367f8e-cf7e-4d0e-a3bb-9fb013ed796a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['previous_gpa', 'current_gpa', 'social_media_impact',\n",
              "       'social_media_hours', 'student_id', 'gpa_consistency',\n",
              "       'scholarship_Yes', 'scholarship_No'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sorted_correlation = correlation_with_y_train.drop('target').abs().sort_values(ascending=False)\n",
        "\n",
        "# Select the top 8 columns\n",
        "top_8_columns = sorted_correlation.head(8).index\n",
        "top_8_columns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUUQtuErLvTh",
        "outputId": "e30ad92e-3f5d-4923-fe36-a94a34849d0d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['student_id', 'age', 'hsc_year', 'current _semester', 'study_hours',\n",
              "       'social_media_hours', 'average_attendance', 'skills_development_hours',\n",
              "       'previous_gpa', 'current_gpa', 'completed_credits', 'house_income',\n",
              "       'gpa_consistency', 'social_media_impact', 'income_academic_score',\n",
              "       'english_proficiency_encoded', 'birth_country_AU', 'birth_country_BR',\n",
              "       'birth_country_CA', 'birth_country_IE', 'birth_country_IN',\n",
              "       'birth_country_NZ', 'birth_country_PH', 'birth_country_TH',\n",
              "       'birth_country_US', 'birth_country_ZA', 'scholarship_No',\n",
              "       'scholarship_Yes', 'university_transport_No',\n",
              "       'university_transport_Yes', 'learning_mode_Offline',\n",
              "       'learning_mode_Online', 'on_probation_No', 'on_probation_Yes',\n",
              "       'is_suspended_No', 'is_suspended_Yes', 'relationship_Engaged',\n",
              "       'relationship_In a relationship', 'relationship_Married',\n",
              "       'relationship_Single'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Getting the list of column in the X_train df\n",
        "features_list = X_train.columns\n",
        "features_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHaIRLAj2_fj"
      },
      "outputs": [],
      "source": [
        "\n",
        "feature_selection_explanations = \"\"\"### Feature Selection Rationale\n",
        "*note all the numerical value are approximate and are subject to change due to randomness*\n",
        "#### **Selected Features**\n",
        "The features chosen for the model—`study_hours`, `social_media_hours`, `previous_gpa`, `current_gpa`, and `on_probation_No`—have strong correlations with the target variable and high predictive relevance. For example:\n",
        "- **`Previous_gpa`**: With a correlation of 0.688, this feature is the strongest predictor of academic performance, reflecting prior achievements.\n",
        "- **`Current_gpa`**: This complements `previous_gpa` with a correlation of -0.543, offering insights into ongoing trends.\n",
        "- **`Social_media_hours`**: Correlated at -0.443, this helps capture behavioral patterns that may negatively impact academic outcomes.\n",
        "- **`Study_hours`**: Correlated at 0.236, this feature provides direct input on time invested in academics.\n",
        "- **`On_probation_No`**: Adds categorical context related to academic status, enhancing predictive accuracy.\n",
        "\n",
        "#### **Reasons for Removing Features**\n",
        "Other features were excluded due to:\n",
        "1. **Weak Correlations**:\n",
        "   - Features like `age` (-0.046) and `skills_development_hours` (-0.048) show negligible relationships with the target variable, contributing little to the model's performance.\n",
        "\n",
        "2. **High Cardinality and Redundancy**:\n",
        "   - Features such as `birth_country` and `relationship_status` add complexity without significant predictive value.\n",
        "\n",
        "3. **Potential Noise**:\n",
        "   - Features like `house_income` (-0.259) and `average_attendance` (-0.242) are less directly connected to academic outcomes and could introduce unnecessary noise into the model.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "GXCmXWx62_kZ",
        "outputId": "f7622c16-3a07-4f06-a19b-03ec42515e07"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<h3 id=\"feature_selection_explanations\">### Feature Selection Rationale\n",
              "*note all the numerical value are approximate and are subject to change due to randomness*\n",
              "#### **Selected Features**\n",
              "The features chosen for the model—`study_hours`, `social_media_hours`, `previous_gpa`, `current_gpa`, and `on_probation_No`—have strong correlations with the target variable and high predictive relevance. For example:\n",
              "- **`Previous_gpa`**: With a correlation of 0.688, this feature is the strongest predictor of academic performance, reflecting prior achievements.\n",
              "- **`Current_gpa`**: This complements `previous_gpa` with a correlation of -0.543, offering insights into ongoing trends.\n",
              "- **`Social_media_hours`**: Correlated at -0.443, this helps capture behavioral patterns that may negatively impact academic outcomes.\n",
              "- **`Study_hours`**: Correlated at 0.236, this feature provides direct input on time invested in academics.\n",
              "- **`On_probation_No`**: Adds categorical context related to academic status, enhancing predictive accuracy.\n",
              "\n",
              "#### **Reasons for Removing Features**\n",
              "Other features were excluded due to:\n",
              "1. **Weak Correlations**:\n",
              "   - Features like `age` (-0.046) and `skills_development_hours` (-0.048) show negligible relationships with the target variable, contributing little to the model's performance.\n",
              "\n",
              "2. **High Cardinality and Redundancy**:\n",
              "   - Features such as `birth_country` and `relationship_status` add complexity without significant predictive value.\n",
              "\n",
              "3. **Potential Noise**:\n",
              "   - Features like `house_income` (-0.259) and `average_attendance` (-0.242) are less directly connected to academic outcomes and could introduce unnecessary noise into the model.\n",
              "</h3>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Do not modify this code\n",
        "print_tile(size=\"h3\", key='feature_selection_explanations', value=feature_selection_explanations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-nNSpJK0Rgu"
      },
      "source": [
        "---\n",
        "## E. Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDtRq1990rcW"
      },
      "source": [
        "### E.1 Data Transformation Robust Scaler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "CTjwyb8mv4re"
      },
      "outputs": [],
      "source": [
        "from re import X\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "# Initialize the Robust Scaler\n",
        "scaler = RobustScaler()\n",
        "\n",
        "# Apply scaling to X_train\n",
        "X_train_robust = scaler.fit_transform(X_train)\n",
        "\n",
        "# Convert back to DataFrame for readability\n",
        "X_train_robust_df = pd.DataFrame(X_train_robust, columns=X_train.columns)\n",
        "\n",
        "X_train=X_train_robust_df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52ZuNAIBv4nX",
        "outputId": "6ac138f0-3489-4bd2-9f15-02d0d7b9523a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Robustly Scaled X_test:\n",
            "      student_id  age  hsc_year  current _semester  study_hours  \\\n",
            "0      0.183658 -1.0       1.0           0.000000         -0.4   \n",
            "1      0.011244 -0.5       0.0           0.000000          0.4   \n",
            "2      0.411544 -1.5       1.0           0.000000         -0.8   \n",
            "3      0.405547  1.0       0.5           0.000000          0.8   \n",
            "4      0.459520 -0.5       0.0           0.000000          0.8   \n",
            "..          ...  ...       ...                ...          ...   \n",
            "145   -0.348576 -1.5       1.0           4.797005          0.4   \n",
            "146   -0.609445 -0.5       1.0           4.797005         -0.4   \n",
            "147   -0.405547 -0.5       0.5           4.797005         -0.4   \n",
            "148   -0.500000 -1.5       0.5           4.797005         -0.4   \n",
            "149   -0.021739  1.0      -2.5           5.411807         -0.8   \n",
            "\n",
            "     social_media_hours  average_attendance  skills_development_hours  \\\n",
            "0             -1.259851            0.227670                  0.000000   \n",
            "1              2.159172           -0.559939                  0.000000   \n",
            "2              0.000000           -0.787610                  1.817059   \n",
            "3              0.000000           -0.787610                  1.817059   \n",
            "4              1.709511            0.256250                  0.000000   \n",
            "..                  ...                 ...                       ...   \n",
            "145            0.000000           -0.787610                  0.000000   \n",
            "146            0.000000           -0.426761                  0.000000   \n",
            "147            0.000000            0.212390                  0.000000   \n",
            "148           -1.709511           -0.559939                  0.000000   \n",
            "149            2.539354            0.212390                  1.817059   \n",
            "\n",
            "     previous_gpa  current_gpa  ...  learning_mode_Offline  \\\n",
            "0        0.018957     0.793220  ...                    0.0   \n",
            "1        0.881517     0.644068  ...                    0.0   \n",
            "2       -0.037915     0.752542  ...                    0.0   \n",
            "3       -0.218009     0.494915  ...                    0.0   \n",
            "4       -0.436019     0.779661  ...                    0.0   \n",
            "..            ...          ...  ...                    ...   \n",
            "145     -0.056872    -0.779661  ...                    0.0   \n",
            "146      0.985782     0.128814  ...                    0.0   \n",
            "147      0.862559     0.128814  ...                    0.0   \n",
            "148      2.094787     0.115254  ...                    0.0   \n",
            "149      0.009479    -1.091525  ...                   -1.0   \n",
            "\n",
            "     learning_mode_Online  on_probation_No  on_probation_Yes  is_suspended_No  \\\n",
            "0                     0.0              0.0               0.0         0.000000   \n",
            "1                     0.0              0.0               0.0         0.000000   \n",
            "2                     0.0              0.0               0.0         0.000000   \n",
            "3                     0.0             -1.0               1.0         0.000000   \n",
            "4                     0.0              0.0               0.0         0.000000   \n",
            "..                    ...              ...               ...              ...   \n",
            "145                   0.0             -1.0               1.0        -3.836079   \n",
            "146                   0.0              0.0               0.0         0.000000   \n",
            "147                   0.0              0.0               0.0         0.000000   \n",
            "148                   0.0             -1.0               1.0         0.000000   \n",
            "149                   1.0             -1.0               1.0        -3.836079   \n",
            "\n",
            "     is_suspended_Yes  relationship_Engaged  relationship_In a relationship  \\\n",
            "0            0.000000                   0.0                        0.000000   \n",
            "1            0.000000                   0.0                        0.000000   \n",
            "2            0.000000                   0.0                        2.683282   \n",
            "3            0.000000                   0.0                        2.683282   \n",
            "4            0.000000                   0.0                        0.000000   \n",
            "..                ...                   ...                             ...   \n",
            "145          3.836079                   0.0                        0.000000   \n",
            "146          0.000000                   0.0                        0.000000   \n",
            "147          0.000000                   0.0                        0.000000   \n",
            "148          0.000000                   0.0                        0.000000   \n",
            "149          3.836079                   0.0                        0.000000   \n",
            "\n",
            "     relationship_Married  relationship_Single  \n",
            "0                0.000000                  0.0  \n",
            "1                0.000000                  0.0  \n",
            "2                0.000000                 -1.0  \n",
            "3                0.000000                 -1.0  \n",
            "4                0.000000                  0.0  \n",
            "..                    ...                  ...  \n",
            "145              0.000000                  0.0  \n",
            "146              0.000000                  0.0  \n",
            "147              0.000000                  0.0  \n",
            "148              0.000000                  0.0  \n",
            "149              2.826669                 -1.0  \n",
            "\n",
            "[150 rows x 40 columns]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Initialize the Robust Scaler\n",
        "scaler = RobustScaler()\n",
        "\n",
        "# Apply scaling to X_test\n",
        "X_test_robust = scaler.fit_transform(X_test)\n",
        "\n",
        "# Convert back to DataFrame for readability\n",
        "X_test_robust_df = pd.DataFrame(X_test_robust, columns=X_test.columns)\n",
        "\n",
        "print(\"\\nRobustly Scaled X_test:\\n\", X_test_robust_df)\n",
        "X_test=X_test_robust_df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jg2tOyEgv4iI",
        "outputId": "cebfd9d3-60c8-4883-d683-e74bc83ef4aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Robustly Scaled X_val:\n",
            "      student_id       age  hsc_year  current _semester  study_hours  \\\n",
            "0      0.339158 -0.333333       0.0               -1.0          0.0   \n",
            "1      0.341407 -0.666667       0.5               -1.0          0.5   \n",
            "2     -0.019383  0.333333       0.0               -1.0         -1.0   \n",
            "3     -0.097534 -0.666667       0.5               -1.0         -0.5   \n",
            "4     -0.083480 -0.333333       0.5               -1.0          0.0   \n",
            "..          ...       ...       ...                ...          ...   \n",
            "143   -0.924456  0.333333      -0.5                1.0         -1.0   \n",
            "144   -0.891701  1.000000       0.0                1.0         -0.5   \n",
            "145   -0.916162  0.666667      -0.5                1.0          0.0   \n",
            "146    0.489057  0.000000      -1.0                1.0         -0.5   \n",
            "147    0.537940  0.000000      -0.5                1.0         -0.5   \n",
            "\n",
            "     social_media_hours  average_attendance  skills_development_hours  \\\n",
            "0              1.646802           -0.588519                       0.0   \n",
            "1             -0.517036            0.441361                       1.0   \n",
            "2              0.728722           -0.588519                      -0.5   \n",
            "3              0.000000            0.669032                      -0.5   \n",
            "4              0.000000            0.727725                       0.0   \n",
            "..                  ...                 ...                       ...   \n",
            "143           -0.517036           -0.588519                       0.5   \n",
            "144           -0.517036            0.569745                       1.0   \n",
            "145            1.245758            0.253961                       0.5   \n",
            "146           -0.517036           -0.588519                       1.5   \n",
            "147            0.401044            0.199091                       0.5   \n",
            "\n",
            "     previous_gpa  current_gpa  ...  learning_mode_Offline  \\\n",
            "0       -0.715054    -0.756757  ...                   -1.0   \n",
            "1       -0.758065    -0.660661  ...                    0.0   \n",
            "2        0.403226     0.528529  ...                    0.0   \n",
            "3        0.360215     0.540541  ...                    0.0   \n",
            "4       -0.704301    -0.636637  ...                   -1.0   \n",
            "..            ...          ...  ...                    ...   \n",
            "143     -0.005376     0.432432  ...                    0.0   \n",
            "144     -0.715054    -0.636637  ...                    0.0   \n",
            "145     -0.403226    -0.144144  ...                    0.0   \n",
            "146      0.607527    -0.348348  ...                   -1.0   \n",
            "147      1.209677    -0.096096  ...                    0.0   \n",
            "\n",
            "     learning_mode_Online  on_probation_No  on_probation_Yes  is_suspended_No  \\\n",
            "0                     1.0              0.0               0.0              0.0   \n",
            "1                     0.0             -1.0               1.0              0.0   \n",
            "2                     0.0              0.0               0.0              0.0   \n",
            "3                     0.0              0.0               0.0              0.0   \n",
            "4                     1.0              0.0               0.0              0.0   \n",
            "..                    ...              ...               ...              ...   \n",
            "143                   0.0              0.0               0.0              0.0   \n",
            "144                   0.0             -1.0               1.0              0.0   \n",
            "145                   0.0             -1.0               1.0              0.0   \n",
            "146                   1.0              0.0               0.0              0.0   \n",
            "147                   0.0              0.0               0.0              0.0   \n",
            "\n",
            "     is_suspended_Yes  relationship_Engaged  relationship_In a relationship  \\\n",
            "0                 0.0                   0.0                             1.0   \n",
            "1                 0.0                   0.0                             1.0   \n",
            "2                 0.0                   0.0                             1.0   \n",
            "3                 0.0                   0.0                             1.0   \n",
            "4                 0.0                   0.0                             0.0   \n",
            "..                ...                   ...                             ...   \n",
            "143               0.0                   0.0                             0.0   \n",
            "144               0.0                   0.0                             1.0   \n",
            "145               0.0                   0.0                             0.0   \n",
            "146               0.0                   0.0                             0.0   \n",
            "147               0.0                   0.0                             0.0   \n",
            "\n",
            "     relationship_Married  relationship_Single  \n",
            "0                     0.0                 -1.0  \n",
            "1                     0.0                 -1.0  \n",
            "2                     0.0                 -1.0  \n",
            "3                     0.0                 -1.0  \n",
            "4                     0.0                  0.0  \n",
            "..                    ...                  ...  \n",
            "143                   0.0                  0.0  \n",
            "144                   0.0                 -1.0  \n",
            "145                   0.0                  0.0  \n",
            "146                   0.0                  0.0  \n",
            "147                   0.0                  0.0  \n",
            "\n",
            "[148 rows x 40 columns]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Initialize the Robust Scaler\n",
        "scaler = RobustScaler()\n",
        "\n",
        "# Apply scaling to X_val\n",
        "X_val_robust = scaler.fit_transform(X_val)\n",
        "\n",
        "# Convert back to DataFrame for readability\n",
        "X_val_robust_df = pd.DataFrame(X_val_robust, columns=X_val.columns)\n",
        "\n",
        "print(\"\\nRobustly Scaled X_val:\\n\", X_val_robust_df)\n",
        "X_val=X_val_robust_df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKhUJOlM3FkC"
      },
      "outputs": [],
      "source": [
        "\n",
        "data_transformation_1_explanations = \"\"\"Data transformation, such as scaling or normalization, is crucial for enhancing the dataset's usability and ensuring robust model performance. For example, scaling using the RobustScaler mitigates the impact of outliers by centering and scaling data within a defined range. This helps in stabilizing variance for skewed features like `study_hours` and `social_media_hours`.\n",
        "\n",
        "### **Importance**\n",
        "1. **Improves Algorithm Efficiency**: Algorithms such as Logistic Regression rely on features being on a similar scale for optimal performance. Without scaling, features with larger ranges (e.g., `previous_gpa`) dominate learning, leading to imbalanced models.\n",
        "\n",
        "2. **Prepares for Robustness**: Features like `current_gpa`, impacted by extreme values, can influence decision boundaries adversely. Transformation controls for these issues.\n",
        "\n",
        "3. **Addresses Variability in Units**: Since different features measure diverse aspects (e.g., `social_media_hours` in hours vs. `previous_gpa` as a score), scaling ensures uniformity across units.\n",
        "\n",
        "---\n",
        "\n",
        "### **Impacts**\n",
        "- **Enhanced Model Performance**: Improves convergence speed and accuracy by making the data more suitable for algorithms.\n",
        "- **Balanced Feature Contribution**: Ensures no single feature disproportionately impacts the model, yielding fair and balanced predictions.\n",
        "- **Improved Generalization**: Scaled data allows the model to make accurate predictions on unseen data.\n",
        "\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "GaWzPi9h3Fqi",
        "outputId": "d3d9a0f7-2ddd-436e-ea5f-a946c7206af5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<h3 id=\"data_transformation_1_explanations\">Data transformation, such as scaling or normalization, is crucial for enhancing the dataset's usability and ensuring robust model performance. For example, scaling using the RobustScaler mitigates the impact of outliers by centering and scaling data within a defined range. This helps in stabilizing variance for skewed features like `study_hours` and `social_media_hours`.\n",
              "\n",
              "### **Importance**\n",
              "1. **Improves Algorithm Efficiency**: Algorithms such as Logistic Regression rely on features being on a similar scale for optimal performance. Without scaling, features with larger ranges (e.g., `previous_gpa`) dominate learning, leading to imbalanced models.\n",
              "\n",
              "2. **Prepares for Robustness**: Features like `current_gpa`, impacted by extreme values, can influence decision boundaries adversely. Transformation controls for these issues.\n",
              "\n",
              "3. **Addresses Variability in Units**: Since different features measure diverse aspects (e.g., `social_media_hours` in hours vs. `previous_gpa` as a score), scaling ensures uniformity across units.\n",
              "\n",
              "---\n",
              "\n",
              "### **Impacts**\n",
              "- **Enhanced Model Performance**: Improves convergence speed and accuracy by making the data more suitable for algorithms.\n",
              "- **Balanced Feature Contribution**: Ensures no single feature disproportionately impacts the model, yielding fair and balanced predictions.\n",
              "- **Improved Generalization**: Scaled data allows the model to make accurate predictions on unseen data.\n",
              "\n",
              "\n",
              "</h3>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Do not modify this code\n",
        "print_tile(size=\"h3\", key='data_transformation_1_explanations', value=data_transformation_1_explanations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S80O7okb0RIx"
      },
      "source": [
        "---\n",
        "## F. Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kst7h7wp1MFK"
      },
      "source": [
        "### F.1 New Feature \"feature selection\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrvOHb0RwJih",
        "outputId": "1f7ace27-c6ec-42cc-fc00-1a14709f4f55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected Features:\n",
            "['study_hours', 'social_media_hours', 'average_attendance', 'previous_gpa', 'current_gpa', 'gpa_consistency', 'birth_country_ZA', 'learning_mode_Offline', 'on_probation_Yes', 'is_suspended_No', 'is_suspended_Yes', 'relationship_Engaged', 'relationship_In a relationship', 'relationship_Married', 'relationship_Single']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "decision_tree = DecisionTreeClassifier(criterion='gini', max_depth=None, random_state=42)\n",
        "model=decision_tree.fit(X_train, y_train)\n",
        "from sklearn.feature_selection import RFE\n",
        "rfe = RFE(estimator=model, n_features_to_select=15)\n",
        "\n",
        "# Perform feature selection\n",
        "X_selected = rfe.fit_transform(X_train, y_train)\n",
        "\n",
        "# Convert the selected features back to a DataFrame\n",
        "# Make sure the number of selected features matches the column names\n",
        "selected_columns = [col for col, selected in zip(X_train.columns, rfe.support_) if selected]\n",
        "X_train_selected = pd.DataFrame(X_selected, columns=selected_columns)\n",
        "\n",
        "# Output the selected features for further processing\n",
        "print(\"Selected Features:\")\n",
        "print(selected_columns)\n",
        "X_train=X_train_selected.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQ3NY95uwJRn",
        "outputId": "25bdaafa-ff05-4a69-8eda-7575b31e0433"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected Features:\n",
            "['study_hours', 'social_media_hours', 'average_attendance', 'previous_gpa', 'current_gpa', 'gpa_consistency', 'birth_country_ZA', 'learning_mode_Offline', 'on_probation_Yes', 'is_suspended_No', 'is_suspended_Yes', 'relationship_Engaged', 'relationship_In a relationship', 'relationship_Married', 'relationship_Single']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "X_val_selected = X_val[selected_columns]\n",
        "\n",
        "# Output the selected features for further processing\n",
        "print(\"Selected Features:\")\n",
        "print(selected_columns)\n",
        "X_val=X_val_selected.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQTtL1tvwJNw",
        "outputId": "e7672e4c-dc79-4316-f5c1-a4c11d2f7173"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected Features:\n",
            "['study_hours', 'social_media_hours', 'average_attendance', 'previous_gpa', 'current_gpa', 'gpa_consistency', 'birth_country_ZA', 'learning_mode_Offline', 'on_probation_Yes', 'is_suspended_No', 'is_suspended_Yes', 'relationship_Engaged', 'relationship_In a relationship', 'relationship_Married', 'relationship_Single']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "X_test_selected = X_test[selected_columns]\n",
        "\n",
        "# Output the selected features for further processing\n",
        "print(\"Selected Features:\")\n",
        "print(selected_columns)\n",
        "X_test=X_test_selected.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Bh6p8D_3hC2"
      },
      "outputs": [],
      "source": [
        "\n",
        "feature_engineering_1_explanations = \"\"\"Creating the feature `social_media_impact` is crucial for understanding the relationship between social media usage and study hours. By quantifying how social media hours affect academic performance, this feature provides actionable insights for identifying students at risk due to poor time management or excessive social media consumption.\n",
        "\n",
        "### **Why It's Important**\n",
        "1. **Behavioral Insight**:\n",
        "   - The feature highlights behavioral patterns that impact academic success, enabling targeted support for students struggling with productivity.\n",
        "\n",
        "2. **Predictive Strength**:\n",
        "   - With a correlation of 0.464983 to the target, it strengthens the model's ability to differentiate students based on their balance between social media use and study hours.\n",
        "\n",
        "### **Impacts**\n",
        "1. **Student Support**:\n",
        "   - Accurate predictions guide interventions for students overly engaged in social media to improve their study habits.\n",
        "\n",
        "2. **Resource Optimization**:\n",
        "   - Institutions can use this feature to design programs promoting better time management and reduce academic underperformance.\n",
        "\n",
        "3. **Improved Model Accuracy**:\n",
        "   - Incorporating this feature refines the model's predictive ability by capturing critical behavioral aspects influencing performance.\n",
        "\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "CBCPPzRB3hFt",
        "outputId": "d5ff618b-6db8-4603-f10a-a85504b991e9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<h3 id=\"feature_engineering_1_explanations\">Creating the feature `social_media_impact` is crucial for understanding the relationship between social media usage and study hours. By quantifying how social media hours affect academic performance, this feature provides actionable insights for identifying students at risk due to poor time management or excessive social media consumption.\n",
              "\n",
              "### **Why It's Important**\n",
              "1. **Behavioral Insight**:\n",
              "   - The feature highlights behavioral patterns that impact academic success, enabling targeted support for students struggling with productivity.\n",
              "\n",
              "2. **Predictive Strength**:\n",
              "   - With a correlation of 0.464983 to the target, it strengthens the model's ability to differentiate students based on their balance between social media use and study hours.\n",
              "\n",
              "### **Impacts**\n",
              "1. **Student Support**:\n",
              "   - Accurate predictions guide interventions for students overly engaged in social media to improve their study habits.\n",
              "\n",
              "2. **Resource Optimization**:\n",
              "   - Institutions can use this feature to design programs promoting better time management and reduce academic underperformance.\n",
              "\n",
              "3. **Improved Model Accuracy**:\n",
              "   - Incorporating this feature refines the model's predictive ability by capturing critical behavioral aspects influencing performance.\n",
              "\n",
              "\n",
              "</h3>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Do not modify this code\n",
        "print_tile(size=\"h3\", key='feature_engineering_1_explanations', value=feature_engineering_1_explanations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8MNBrC4Zgz6"
      },
      "source": [
        "---\n",
        "## G. Train Machine Learning Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_tQitOfeDXr"
      },
      "source": [
        "### G.1 Import Algorithm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Mh6epkAThez5"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOzgowlJ3uyp"
      },
      "outputs": [],
      "source": [
        "\n",
        "algorithm_selection_explanations = \"\"\"\n",
        "### Why DecisionTreeClassifier Is a Good Fit\n",
        "\n",
        "DecisionTreeClassifier is a strong choice for this project due to its interpretability and versatility. Here's why:\n",
        "\n",
        "1. **Handles Nonlinear Relationships**:\n",
        "   - Decision trees excel at capturing complex, nonlinear interactions between features, such as `study_hours`, `previous_gpa`, and `social_media_impact`.\n",
        "\n",
        "2. **No Need for Preprocessing**:\n",
        "   - It doesn't require scaling or normalization of features, making it ideal for datasets with diverse units.\n",
        "\n",
        "3. **Interpretable Structure**:\n",
        "   - The tree structure makes predictions and feature importance easily interpretable, helping stakeholders understand how decisions are made.\n",
        "\n",
        "4. **Flexible Multiclass Classification**:\n",
        "   - Decision trees can classify student performance into multiple categories (\"Poor,\" \"Average,\" \"Good,\" \"Excellent\") without additional modifications.\n",
        "\n",
        "5. **Works Well for Imbalanced Data**:\n",
        "   - While it may require tuning to handle imbalanced datasets, DecisionTreeClassifier can prioritize majority classes effectively and make adjustments through hyperparameters like `class_weight`.\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "BYNgEFLX3u17",
        "outputId": "7c89135f-7df3-4ea3-f593-74f256ee90b3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<h3 id=\"algorithm_selection_explanations\">\n",
              "### Why DecisionTreeClassifier Is a Good Fit\n",
              "\n",
              "DecisionTreeClassifier is a strong choice for this project due to its interpretability and versatility. Here's why:\n",
              "\n",
              "1. **Handles Nonlinear Relationships**:\n",
              "   - Decision trees excel at capturing complex, nonlinear interactions between features, such as `study_hours`, `previous_gpa`, and `social_media_impact`.\n",
              "\n",
              "2. **No Need for Preprocessing**:\n",
              "   - It doesn't require scaling or normalization of features, making it ideal for datasets with diverse units.\n",
              "\n",
              "3. **Interpretable Structure**:\n",
              "   - The tree structure makes predictions and feature importance easily interpretable, helping stakeholders understand how decisions are made.\n",
              "\n",
              "4. **Flexible Multiclass Classification**:\n",
              "   - Decision trees can classify student performance into multiple categories (\"Poor,\" \"Average,\" \"Good,\" \"Excellent\") without additional modifications.\n",
              "\n",
              "5. **Works Well for Imbalanced Data**:\n",
              "   - While it may require tuning to handle imbalanced datasets, DecisionTreeClassifier can prioritize majority classes effectively and make adjustments through hyperparameters like `class_weight`.\n",
              "\n",
              "</h3>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Do not modify this code\n",
        "print_tile(size=\"h3\", key='algorithm_selection_explanations', value=algorithm_selection_explanations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ks_MmM2mCfm"
      },
      "source": [
        "### G.2 Set Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "NUswpGVLmDXl"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Initialize the Decision Tree classifier\n",
        "decision_tree = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=42)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_hjiXab31B3"
      },
      "outputs": [],
      "source": [
        "\n",
        "hyperparameters_selection_explanations = \"\"\"\n",
        "\n",
        "\n",
        "### Explanation of Tuning for DecisionTreeClassifier\n",
        "- **`criterion='gini'`**:\n",
        "   - Gini impurity measures the quality of splits. It ensures each split minimizes the likelihood of incorrect classifications.\n",
        "\n",
        "- **`max_depth=None`**:\n",
        "   - This allows the tree to grow until all leaves are pure or the dataset is fully classified. While it captures maximum detail, it can lead to overfitting.\n",
        "\n",
        "- **`random_state=42`**:\n",
        "   - Ensures reproducibility by controlling the randomness of the tree-building process.\n",
        "\n",
        "### Impacts:\n",
        "- While `max_depth` allows detailed learning, tuning it (e.g., limiting depth) might help reduce overfitting.\n",
        "- Decision Tree’s flexibility with hyperparameters ensures it adapts well to the project's specific needs.\n",
        "\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "tcZOBvcv31E5",
        "outputId": "b3188421-501d-4d00-f074-c7753046ae34"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<h3 id=\"hyperparameters_selection_explanations\">\n",
              "\n",
              "\n",
              "### Explanation of Tuning for DecisionTreeClassifier\n",
              "- **`criterion='gini'`**:\n",
              "   - Gini impurity measures the quality of splits. It ensures each split minimizes the likelihood of incorrect classifications.\n",
              "\n",
              "- **`max_depth=None`**:\n",
              "   - This allows the tree to grow until all leaves are pure or the dataset is fully classified. While it captures maximum detail, it can lead to overfitting.\n",
              "\n",
              "- **`random_state=42`**:\n",
              "   - Ensures reproducibility by controlling the randomness of the tree-building process.\n",
              "\n",
              "### Impacts:\n",
              "- While `max_depth` allows detailed learning, tuning it (e.g., limiting depth) might help reduce overfitting.\n",
              "- Decision Tree’s flexibility with hyperparameters ensures it adapts well to the project's specific needs.\n",
              "\n",
              "\n",
              "</h3>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Do not modify this code\n",
        "print_tile(size=\"h3\", key='hyperparameters_selection_explanations', value=hyperparameters_selection_explanations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDjdjQjFmkLe"
      },
      "source": [
        "### G.3 Fit Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ub3Nrdgmm2N",
        "outputId": "97f8dab1-4e9d-4a8d-820c-8268b388a183"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "[[64 12 10  2]\n",
            " [ 0 19 24  4]\n",
            " [ 0  0 11  0]\n",
            " [ 0  0  2  0]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.73      0.84        88\n",
            "         1.0       0.61      0.40      0.49        47\n",
            "         2.0       0.23      1.00      0.38        11\n",
            "         3.0       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.64       148\n",
            "   macro avg       0.46      0.53      0.43       148\n",
            "weighted avg       0.81      0.64      0.68       148\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Fit the model to the training data\n",
        "decision_tree.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Predict the classes for the val data\n",
        "y_pred = decision_tree.predict(X_val)\n",
        "# Evaluate the model\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_val, y_pred))\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_val, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q43YtqpdeniY"
      },
      "source": [
        "### G.4 Model Technical Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1Q3oxoNhez5",
        "outputId": "636c71eb-e324-418e-ec63-6b7823f414c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "[[48 12  8  2]\n",
            " [ 1 31 18  4]\n",
            " [ 0  3 15  0]\n",
            " [ 0  0  8  0]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      0.69      0.81        70\n",
            "         1.0       0.67      0.57      0.62        54\n",
            "         2.0       0.31      0.83      0.45        18\n",
            "         3.0       0.00      0.00      0.00         8\n",
            "\n",
            "    accuracy                           0.63       150\n",
            "   macro avg       0.49      0.52      0.47       150\n",
            "weighted avg       0.74      0.63      0.65       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Predict the classes for the test data\n",
        "y_pred = decision_tree.predict(X_test)\n",
        "# Evaluate the model\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7movz2AD3-k_"
      },
      "outputs": [],
      "source": [
        "\n",
        "model_performance_explanations = \"\"\"\n",
        "### Model Performance Explanation\n",
        "\n",
        "The DecisionTreeClassifier performs well for identifying \"Poor\" students, with high recall (81% validation, 86% test). However, it struggles with minority classes like \"Excellent\" due to imbalanced data. Improvements like addressing class imbalance or limiting tree depth could enhance performance. The model meets the primary goal of focusing on at-risk students.\n",
        "\n",
        "### **Key Observations**\n",
        "1. **Strengths**:\n",
        "   - The model reliably identifies students in the \"Poor\" category, supporting the business goal of targeting at-risk students.\n",
        "   - Strong recall for \"Poor\" (86% on test) ensures most at-risk individuals are captured.\n",
        "\n",
        "2. **Weaknesses**:\n",
        "   - Minority classes like \"Excellent\" and \"Good\" are poorly predicted due to imbalanced data.\n",
        "   - Macro averages highlight uneven performance across categories.\n",
        "\n",
        "---\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "1U_nKfW93-t0",
        "outputId": "40140e1c-d227-481a-849b-c4202ef07933"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<h3 id=\"model_performance_explanations\">\n",
              "### Model Performance Explanation\n",
              "\n",
              "The DecisionTreeClassifier performs well for identifying \"Poor\" students, with high recall (81% validation, 86% test). However, it struggles with minority classes like \"Excellent\" due to imbalanced data. Improvements like addressing class imbalance or limiting tree depth could enhance performance. The model meets the primary goal of focusing on at-risk students.\n",
              "\n",
              "### **Key Observations**\n",
              "1. **Strengths**:\n",
              "   - The model reliably identifies students in the \"Poor\" category, supporting the business goal of targeting at-risk students.\n",
              "   - Strong recall for \"Poor\" (86% on test) ensures most at-risk individuals are captured.\n",
              "\n",
              "2. **Weaknesses**:\n",
              "   - Minority classes like \"Excellent\" and \"Good\" are poorly predicted due to imbalanced data.\n",
              "   - Macro averages highlight uneven performance across categories.\n",
              "\n",
              "---\n",
              "</h3>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "# Do not modify this code\n",
        "print_tile(size=\"h3\", key='model_performance_explanations', value=model_performance_explanations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1HgZMPcmtu7"
      },
      "source": [
        "### G.5 Business Impact from Current Model Performance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7zWIZ4v4Ehd"
      },
      "outputs": [],
      "source": [
        "\n",
        "business_impacts_explanations = \"\"\"Results Related to Business Objective\n",
        "The DecisionTreeClassifier successfully meets the primary business goal of identifying at-risk students (\"Poor\" category) with strong recall (81% validation, 86% test). This ensures most students needing intervention are correctly classified. However, performance for minority classes like \"Excellent\" remains weak, limiting insights into high-performing students.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "id": "OfuoUsp84Eod",
        "outputId": "34c37ab3-b8ab-48cf-d6f0-ddb122b8a139"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<h3 id=\"business_impacts_explanations\">Results Related to Business Objective\n",
              "The DecisionTreeClassifier successfully meets the primary business goal of identifying at-risk students (\"Poor\" category) with strong recall (81% validation, 86% test). This ensures most students needing intervention are correctly classified. However, performance for minority classes like \"Excellent\" remains weak, limiting insights into high-performing students.\n",
              "</h3>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Do not modify this code\n",
        "print_tile(size=\"h3\", key='business_impacts_explanations', value=business_impacts_explanations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mp1Ie9o8nDl1"
      },
      "source": [
        "## H. Experiment Outcomes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1ks62SL4KEk"
      },
      "outputs": [],
      "source": [
        "\n",
        "experiment_outcome = \"Hypothesis Partially Confirmed\" # Either 'Hypothesis Confirmed', 'Hypothesis Partially Confirmed' or 'Hypothesis Rejected'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "1Z2YIMpr4KLJ",
        "outputId": "1a286e7a-83d8-4756-ad53-ab278180612f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<h2 id=\"experiment_outcomes_explanations\">Hypothesis Partially Confirmed</h2>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Do not modify this code\n",
        "print_tile(size=\"h2\", key='experiment_outcomes_explanations', value=experiment_outcome)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tw5lZ2S4KV3"
      },
      "outputs": [],
      "source": [
        "\n",
        "experiment_results_explanations = \"\"\"### Reflection on Experiment Outcome\n",
        "\n",
        "#### **Outcome**\n",
        "The experiment achieved the main business objective, focusing on identifying students in the \"Poor\" category with high recall (86% on test data) and satisfactory F1-scores (validation: 74%, test: 72%). However, predictions for minority classes like \"Excellent\" were weak, reflecting imbalanced data and potential limitations of the DecisionTreeClassifier.\n",
        "\n",
        "#### **Insights Gained**\n",
        "1. **\"Poor\" Category Focus**:\n",
        "   - The model excels in identifying at-risk students, which directly supports targeted interventions.\n",
        "\n",
        "2. **Imbalanced Data Challenges**:\n",
        "   - Minority class predictions were weak, confirming that imbalanced datasets require strategies like class-weight adjustments or oversampling.\n",
        "\n",
        "3. **Potential Overfitting**:\n",
        "   - The model performed better on validation data compared to test data, indicating a need for generalization improvements.\n",
        "\n",
        "---\n",
        "\n",
        "### **Rationale for Further Experimentation**\n",
        "Further experimentation is worthwhile to address overfitting and enhance robustness in predictions for the primary category. Exploring techniques to refine predictions for minority classes may add secondary value but is less critical to the main objective.\n",
        "\n",
        "---\n",
        "\n",
        "### **Potential Next Steps**\n",
        "**1. Optimize for Generalization**\n",
        "   - **Action**: Limit `max_depth` or apply pruning to reduce overfitting.\n",
        "   - **Expected Uplift**: Enhanced test accuracy and consistency in predictions.\n",
        "   - **Ranking**: **High Priority**\n",
        "\n",
        "**2. Address Class Imbalance**\n",
        "   - **Action**: Use SMOTE or class-weight adjustments.\n",
        "   - **Expected Uplift**: Improved recall and precision for minority classes.\n",
        "   - **Ranking**: **Medium Priority**\n",
        "\n",
        "**3. Experiment with Ensemble Methods**\n",
        "   - **Action**: Test Random Forest or Boosting algorithms to combine the strengths of multiple trees.\n",
        "   - **Expected Uplift**: Higher accuracy and balanced predictions across classes.\n",
        "   - **Ranking**: **Medium Priority**\n",
        "\n",
        "---\n",
        "\n",
        "### **Deployment Recommendation**\n",
        "If improvements focus effectively on the \"Poor\" category without significantly altering the current performance, the model is ready for production deployment. Steps to deploy include:\n",
        "1. **Monitoring**: Implement a framework to track model predictions and ensure continued alignment with the business goal.\n",
        "2. **Stakeholder Training**: Prepare users to interpret results and implement targeted interventions.\n",
        "3. **Documentation**: Clearly outline the model’s strengths, limitations, and usage instructions.\n",
        "\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "H-Zd7BEz4Kc3",
        "outputId": "9bf6d882-9cfb-446f-9416-e9750ec38023"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<h2 id=\"experiment_results_explanations\">### Reflection on Experiment Outcome\n",
              "\n",
              "#### **Outcome**\n",
              "The experiment achieved the main business objective, focusing on identifying students in the \"Poor\" category with high recall (86% on test data) and satisfactory F1-scores (validation: 74%, test: 72%). However, predictions for minority classes like \"Excellent\" were weak, reflecting imbalanced data and potential limitations of the DecisionTreeClassifier.\n",
              "\n",
              "#### **Insights Gained**\n",
              "1. **\"Poor\" Category Focus**:\n",
              "   - The model excels in identifying at-risk students, which directly supports targeted interventions.\n",
              "\n",
              "2. **Imbalanced Data Challenges**:\n",
              "   - Minority class predictions were weak, confirming that imbalanced datasets require strategies like class-weight adjustments or oversampling.\n",
              "\n",
              "3. **Potential Overfitting**:\n",
              "   - The model performed better on validation data compared to test data, indicating a need for generalization improvements.\n",
              "\n",
              "---\n",
              "\n",
              "### **Rationale for Further Experimentation**\n",
              "Further experimentation is worthwhile to address overfitting and enhance robustness in predictions for the primary category. Exploring techniques to refine predictions for minority classes may add secondary value but is less critical to the main objective.\n",
              "\n",
              "---\n",
              "\n",
              "### **Potential Next Steps**\n",
              "**1. Optimize for Generalization**\n",
              "   - **Action**: Limit `max_depth` or apply pruning to reduce overfitting.\n",
              "   - **Expected Uplift**: Enhanced test accuracy and consistency in predictions.\n",
              "   - **Ranking**: **High Priority**\n",
              "\n",
              "**2. Address Class Imbalance**\n",
              "   - **Action**: Use SMOTE or class-weight adjustments.\n",
              "   - **Expected Uplift**: Improved recall and precision for minority classes.\n",
              "   - **Ranking**: **Medium Priority**\n",
              "\n",
              "**3. Experiment with Ensemble Methods**\n",
              "   - **Action**: Test Random Forest or Boosting algorithms to combine the strengths of multiple trees.\n",
              "   - **Expected Uplift**: Higher accuracy and balanced predictions across classes.\n",
              "   - **Ranking**: **Medium Priority**\n",
              "\n",
              "---\n",
              "\n",
              "### **Deployment Recommendation**\n",
              "If improvements focus effectively on the \"Poor\" category without significantly altering the current performance, the model is ready for production deployment. Steps to deploy include:\n",
              "1. **Monitoring**: Implement a framework to track model predictions and ensure continued alignment with the business goal.\n",
              "2. **Stakeholder Training**: Prepare users to interpret results and implement targeted interventions.\n",
              "3. **Documentation**: Clearly outline the model’s strengths, limitations, and usage instructions.\n",
              "\n",
              "\n",
              "</h2>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Do not modify this code\n",
        "print_tile(size=\"h2\", key='experiment_results_explanations', value=experiment_results_explanations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rI-7hD7iTS_9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "student-at-risk-detector-py3.13",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
